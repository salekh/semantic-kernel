{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a80181",
   "metadata": {},
   "source": [
    "# Introduction to the Planner\n",
    "\n",
    "The Planner is one of the fundamental concepts of the Semantic Kernel.\n",
    "\n",
    "It makes use of the collection of native and semantic functions that have been registered to the kernel and using AI, will formulate a plan to execute the given ask.\n",
    "\n",
    "From our own testing, planner works best with more powerful models like `gpt4` but sometimes you might get working plans with cheaper models like `gpt-35-turbo`. We encourage you to implement your own versions of the planner and use different models that fit your user needs.\n",
    "\n",
    "Read more about planner [here](https://aka.ms/sk/concepts/planner).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf9c0e",
   "metadata": {},
   "source": [
    "Import Semantic Kernel SDK from pypi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07eb35d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semantic-kernel in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (1.18.2)\n",
      "Requirement already satisfied: aiohttp~=3.8 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (3.11.11)\n",
      "Requirement already satisfied: cloudevents~=1.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (1.11.0)\n",
      "Requirement already satisfied: pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (2.9.2)\n",
      "Requirement already satisfied: pydantic-settings~=2.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (2.7.1)\n",
      "Requirement already satisfied: defusedxml~=0.7 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: azure-identity~=1.13 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (1.19.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (2.1.2)\n",
      "Requirement already satisfied: openai~=1.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (1.59.9)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (0.19.4)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (1.29.0)\n",
      "Requirement already satisfied: prance~=23.6.21.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (23.6.21.0)\n",
      "Requirement already satisfied: pybars4~=0.9 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (0.9.13)\n",
      "Requirement already satisfied: jinja2~=3.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (3.1.5)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (1.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (1.18.3)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from azure-identity~=1.13->semantic-kernel) (1.32.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from azure-identity~=1.13->semantic-kernel) (44.0.0)\n",
      "Requirement already satisfied: msal>=1.30.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from azure-identity~=1.13->semantic-kernel) (1.31.1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from azure-identity~=1.13->semantic-kernel) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from azure-identity~=1.13->semantic-kernel) (4.12.2)\n",
      "Requirement already satisfied: deprecation<3.0,>=2.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from cloudevents~=1.0->semantic-kernel) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from jinja2~=3.1->semantic-kernel) (3.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openai~=1.0->semantic-kernel) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openai~=1.0->semantic-kernel) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openai~=1.0->semantic-kernel) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openai~=1.0->semantic-kernel) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openai~=1.0->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openai~=1.0->semantic-kernel) (4.67.1)\n",
      "Requirement already satisfied: isodate in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.3.3)\n",
      "Requirement already satisfied: more-itertools in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.6.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.6.3)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: parse in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (1.20.2)\n",
      "Requirement already satisfied: werkzeug in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (3.1.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from opentelemetry-api~=1.24->semantic-kernel) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from opentelemetry-api~=1.24->semantic-kernel) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from opentelemetry-sdk~=1.24->semantic-kernel) (0.50b0)\n",
      "Requirement already satisfied: chardet>=3.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from prance~=23.6.21.0->semantic-kernel) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.10 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from prance~=23.6.21.0->semantic-kernel) (0.18.10)\n",
      "Requirement already satisfied: requests>=2.25 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from prance~=23.6.21.0->semantic-kernel) (2.32.3)\n",
      "Requirement already satisfied: six~=1.15 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from prance~=23.6.21.0->semantic-kernel) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from prance~=23.6.21.0->semantic-kernel) (24.1)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from pybars4~=0.9->semantic-kernel) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0->semantic-kernel) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0->semantic-kernel) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from pydantic-settings~=2.0->semantic-kernel) (1.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai~=1.0->semantic-kernel) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai~=1.0->semantic-kernel) (3.10)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from cryptography>=2.5->azure-identity~=1.13->semantic-kernel) (1.17.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.24->semantic-kernel) (1.17.2)\n",
      "Requirement already satisfied: certifi in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel) (3.20.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.22.3)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (6.0.2)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (0.4.4)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity~=1.13->semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from msal-extensions>=1.2.0->azure-identity~=1.13->semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: rfc3339-validator in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel) (1.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.25->prance~=23.6.21.0->semantic-kernel) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.25->prance~=23.6.21.0->semantic-kernel) (2.2.3)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from ruamel.yaml>=0.17.10->prance~=23.6.21.0->semantic-kernel) (0.2.12)\n",
      "Requirement already satisfied: pycparser in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity~=1.13->semantic-kernel) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.18.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: if using a virtual environment, do not run this cell\n",
    "%pip install -U semantic-kernel\n",
    "from semantic_kernel import __version__\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e96d7",
   "metadata": {},
   "source": [
    "Initial configuration for the notebook to run properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d9ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure paths are correct for the imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "\n",
    "sys.path.append(grandparent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcd7e04",
   "metadata": {},
   "source": [
    "### Configuring the Kernel\n",
    "\n",
    "Let's get started with the necessary configuration to run Semantic Kernel. For Notebooks, we require a `.env` file with the proper settings for the model you use. Create a new file named `.env` and place it in this directory. Copy the contents of the `.env.example` file from this directory and paste it into the `.env` file that you just created.\n",
    "\n",
    "**NOTE: Please make sure to include `GLOBAL_LLM_SERVICE` set to either OpenAI, AzureOpenAI, or HuggingFace in your .env file. If this setting is not included, the Service will default to AzureOpenAI.**\n",
    "\n",
    "#### Option 1: using OpenAI\n",
    "\n",
    "Add your [OpenAI Key](https://openai.com/product/) key to your `.env` file (org Id only if you have multiple orgs):\n",
    "\n",
    "```\n",
    "GLOBAL_LLM_SERVICE=\"OpenAI\"\n",
    "OPENAI_API_KEY=\"sk-...\"\n",
    "OPENAI_ORG_ID=\"\"\n",
    "OPENAI_CHAT_MODEL_ID=\"\"\n",
    "OPENAI_TEXT_MODEL_ID=\"\"\n",
    "OPENAI_EMBEDDING_MODEL_ID=\"\"\n",
    "```\n",
    "The names should match the names used in the `.env` file, as shown above.\n",
    "\n",
    "#### Option 2: using Azure OpenAI\n",
    "\n",
    "Add your [Azure Open AI Service key](https://learn.microsoft.com/azure/cognitive-services/openai/quickstart?pivots=programming-language-studio) settings to the `.env` file in the same folder:\n",
    "\n",
    "```\n",
    "GLOBAL_LLM_SERVICE=\"AzureOpenAI\"\n",
    "AZURE_OPENAI_API_KEY=\"...\"\n",
    "AZURE_OPENAI_ENDPOINT=\"https://...\"\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_TEXT_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_API_VERSION=\"...\"\n",
    "```\n",
    "The names should match the names used in the `.env` file, as shown above.\n",
    "\n",
    "For more advanced configuration, please follow the steps outlined in the [setup guide](./CONFIGURING_THE_KERNEL.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907665d",
   "metadata": {},
   "source": [
    "We will load our settings and get the LLM service to use for the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a1e3c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using service type: Service.AzureOpenAI\n"
     ]
    }
   ],
   "source": [
    "from services import Service\n",
    "\n",
    "from samples.service_settings import ServiceSettings\n",
    "\n",
    "service_settings = ServiceSettings.create()\n",
    "\n",
    "# Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
    "selectedService = (\n",
    "    Service.AzureOpenAI\n",
    "    if service_settings.global_llm_service is None\n",
    "    else Service(service_settings.global_llm_service.lower())\n",
    ")\n",
    "print(f\"Using service type: {selectedService}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d888f62",
   "metadata": {},
   "source": [
    "Let's define some imports that will be used in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3852961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents.chat_history import ChatHistory  # noqa: F401\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments  # noqa: F401\n",
    "from semantic_kernel.prompt_template.input_variable import InputVariable  # noqa: F401"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deff5675",
   "metadata": {},
   "source": [
    "Define your ASK. What do you want the Kernel to do?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "925b4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"\"\"\n",
    "Tomorrow is Valentine's day. I need to come up with a few short poems.\n",
    "She likes Shakespeare so write using his style. She speaks French so write it in French.\n",
    "Convert the text to uppercase.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61bacf1",
   "metadata": {},
   "source": [
    "### Providing plugins to the planner\n",
    "\n",
    "The planner needs to know what plugins are available to it. Here we'll give it access to the `SummarizePlugin` and `WriterPlugin` we have defined on disk. This will include many semantic functions, of which the planner will intelligently choose a subset.\n",
    "\n",
    "You can also include native functions as well. Here we'll add the TextPlugin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3161dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plugin: SummarizePlugin, Function: Topics\n",
      "Plugin: SummarizePlugin, Function: MakeAbstractReadable\n",
      "Plugin: SummarizePlugin, Function: Notegen\n",
      "Plugin: SummarizePlugin, Function: Summarize\n",
      "Plugin: WriterPlugin, Function: NovelChapterWithNotes\n",
      "Plugin: WriterPlugin, Function: EmailTo\n",
      "Plugin: WriterPlugin, Function: Acronym\n",
      "Plugin: WriterPlugin, Function: ShortPoem\n",
      "Plugin: WriterPlugin, Function: Rewrite\n",
      "Plugin: WriterPlugin, Function: Brainstorm\n",
      "Plugin: WriterPlugin, Function: EnglishImprover\n",
      "Plugin: WriterPlugin, Function: AcronymGenerator\n",
      "Plugin: WriterPlugin, Function: Translate\n",
      "Plugin: WriterPlugin, Function: TwoSentenceSummary\n",
      "Plugin: WriterPlugin, Function: NovelOutline\n",
      "Plugin: WriterPlugin, Function: EmailGen\n",
      "Plugin: WriterPlugin, Function: NovelChapter\n",
      "Plugin: WriterPlugin, Function: StoryGen\n",
      "Plugin: WriterPlugin, Function: AcronymReverse\n",
      "Plugin: WriterPlugin, Function: TellMeMore\n",
      "Plugin: WriterPlugin, Function: Shakespeare\n",
      "Plugin: TextPlugin, Function: lowercase\n",
      "Plugin: TextPlugin, Function: trim\n",
      "Plugin: TextPlugin, Function: trim_end\n",
      "Plugin: TextPlugin, Function: trim_start\n",
      "Plugin: TextPlugin, Function: uppercase\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings\n",
    "from semantic_kernel.core_plugins.text_plugin import TextPlugin\n",
    "from semantic_kernel.functions.kernel_function_from_prompt import KernelFunctionFromPrompt\n",
    "from semantic_kernel.kernel import Kernel\n",
    "\n",
    "kernel = Kernel()\n",
    "service_id = None\n",
    "if selectedService == Service.OpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        OpenAIChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )\n",
    "elif selectedService == Service.AzureOpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "plugins_directory = \"../../../prompt_template_samples/\"\n",
    "summarize_plugin = kernel.add_plugin(plugin_name=\"SummarizePlugin\", parent_directory=plugins_directory)\n",
    "writer_plugin = kernel.add_plugin(\n",
    "    plugin_name=\"WriterPlugin\",\n",
    "    parent_directory=plugins_directory,\n",
    ")\n",
    "text_plugin = kernel.add_plugin(plugin=TextPlugin(), plugin_name=\"TextPlugin\")\n",
    "\n",
    "shakespeare_func = KernelFunctionFromPrompt(\n",
    "    function_name=\"Shakespeare\",\n",
    "    plugin_name=\"WriterPlugin\",\n",
    "    prompt=\"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Rewrite the above in the style of Shakespeare.\n",
    "\"\"\",\n",
    "    prompt_execution_settings=OpenAIChatPromptExecutionSettings(\n",
    "        service_id=service_id,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.8,\n",
    "    ),\n",
    "    description=\"Rewrite the input in the style of Shakespeare.\",\n",
    ")\n",
    "kernel.add_function(plugin_name=\"WriterPlugin\", function=shakespeare_func)\n",
    "\n",
    "for plugin_name, plugin in kernel.plugins.items():\n",
    "    for function_name, function in plugin.functions.items():\n",
    "        print(f\"Plugin: {plugin_name}, Function: {function_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9b6b7",
   "metadata": {},
   "source": [
    "# The Plan Object Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50f8859",
   "metadata": {},
   "source": [
    "To build more advanced planners, we need to introduce a proper Plan object that can contain all the necessary state and information needed for high quality plans.\n",
    "\n",
    "To see what that object model is, look at (https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planners/plan.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0cb2a2",
   "metadata": {},
   "source": [
    "# Sequential Planner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c66d83",
   "metadata": {},
   "source": [
    "The sequential planner is an XML-based step-by-step planner. You can see the prompt used for it [here](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planners/sequential_planner/Plugins/SequentialPlanning/skprompt.txt).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2e90624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planners import SequentialPlanner\n",
    "\n",
    "planner = SequentialPlanner(kernel, service_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d537981",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_plan = await planner.create_plan(goal=ask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2f462b",
   "metadata": {},
   "source": [
    "To see the steps that the Sequential Planner will take, we can iterate over them and print their descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7007418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The plan's steps are:\n",
      "- Turn a scenario into a short and entertaining poem using WriterPlugin-ShortPoem with parameters: {'input': \"Valentine's Day scenario\"}\n",
      "- Rewrite the input in the style of Shakespeare using WriterPlugin-Shakespeare with parameters: {'input': '$POEM'}\n",
      "- Translate the input into a language of your choice using WriterPlugin-Translate with parameters: {'input': '$SHAKESPEARE_POEM', 'language': 'French'}\n",
      "- Convert a string to uppercase using TextPlugin-uppercase with parameters: {'input': '$FRENCH_POEM'}\n"
     ]
    }
   ],
   "source": [
    "print(\"The plan's steps are:\")\n",
    "for step in sequential_plan._steps:\n",
    "    print(\n",
    "        f\"- {step.description.replace('.', '') if step.description else 'No description'} using {step.metadata.fully_qualified_name} with parameters: {step.parameters}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db5f844",
   "metadata": {},
   "source": [
    "Let's ask the sequential planner to execute the plan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88411884",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await sequential_plan.invoke(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36d27aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LE JOUR DE L'AMOUR, QUAND LES CŒURS PRENNENT LEUR ENVOL,  \n",
      "CUPIDON, MALICE DANS LES YEUX, PERDIT LA VUE.  \n",
      "SA FLÈCHE, CAPRICIEUSE, RENCONTRA UNE VIEILLE CHAUSSURE,  \n",
      "UNE QUEUE DE FÉLIN, ET UN RAGOÛT BOUILLONNANT,  \n",
      "LAISSANT LES AMANTS PRIS DANS LE CRUEL PIÈGE DU MALHEUR.\n",
      "\n",
      "UN GENTILHOMME, SA BIEN-AIMÉE AVEC UNE FLEUR EN MAIN,  \n",
      "ÉTERNUA, ET VOILÀ, LA ROSE S'ENVOLA,  \n",
      "ATTERRISSANT NULLE PART AILLEURS QUE SUR LA RIVE LÀ-BAS.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789b651a",
   "metadata": {},
   "source": [
    "# Function Calling Stepwise Planner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4bbcc3",
   "metadata": {},
   "source": [
    "The Function Calling Stepwise Planner is based off the paper from MRKL (Modular Reasoning, Knowledge and Language) and is similar to other papers like ReACT (Reasoning and Acting in Language Models). At the core, the stepwise planner allows for the AI to form \"thoughts\" and \"observations\" and execute actions based off those to achieve a user's goal. This continues until all required functions are complete and a final output is generated.\n",
    "\n",
    "Please note that the Function Calling Stepwise Planner uses OpenAI function calling, and so it can only use either the AzureChatCompletion or the OpenAIChatCompletion service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "771bafa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.kernel import Kernel\n",
    "\n",
    "kernel = Kernel()\n",
    "service_id = None\n",
    "if selectedService == Service.OpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        OpenAIChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )\n",
    "elif selectedService == Service.AzureOpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a00bde",
   "metadata": {},
   "source": [
    "Let's create a sample `EmailPlugin` that simulates handling a request to `get_email_address()` and `send_email()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cb43d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from semantic_kernel.functions.kernel_function_decorator import kernel_function\n",
    "\n",
    "\n",
    "class EmailPlugin:\n",
    "    \"\"\"\n",
    "    Description: EmailPlugin provides a set of functions to send emails.\n",
    "\n",
    "    Usage:\n",
    "        kernel.import_plugin_from_object(EmailPlugin(), plugin_name=\"email\")\n",
    "\n",
    "    Examples:\n",
    "        {{email.SendEmail}} => Sends an email with the provided subject and body.\n",
    "    \"\"\"\n",
    "\n",
    "    @kernel_function(name=\"SendEmail\", description=\"Given an e-mail and message body, send an e-email\")\n",
    "    def send_email(\n",
    "        self,\n",
    "        subject: Annotated[str, \"the subject of the email\"],\n",
    "        body: Annotated[str, \"the body of the email\"],\n",
    "    ) -> Annotated[str, \"the output is a string\"]:\n",
    "        \"\"\"Sends an email with the provided subject and body.\"\"\"\n",
    "        return f\"Email sent with subject: {subject} and body: {body}\"\n",
    "\n",
    "    @kernel_function(name=\"GetEmailAddress\", description=\"Given a name, find the email address\")\n",
    "    def get_email_address(\n",
    "        self,\n",
    "        input: Annotated[str, \"the name of the person\"],\n",
    "    ):\n",
    "        email = \"\"\n",
    "        if input == \"Jane\":\n",
    "            email = \"janedoe4321@example.com\"\n",
    "        elif input == \"Paul\":\n",
    "            email = \"paulsmith5678@example.com\"\n",
    "        elif input == \"Mary\":\n",
    "            email = \"maryjones8765@example.com\"\n",
    "        else:\n",
    "            email = \"johndoe1234@example.com\"\n",
    "        return email"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feef46b",
   "metadata": {},
   "source": [
    "We'll add this new plugin to the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "032d5981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='EmailPlugin', description=None, functions={'GetEmailAddress': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='GetEmailAddress', plugin_name='EmailPlugin', description='Given a name, find the email address', parameters=[KernelParameterMetadata(name='input', description='the name of the person', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string', 'description': 'the name of the person'}, include_in_function_choices=True)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='Any', is_required=True, type_object=None, schema_data={'type': 'object'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6f130>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6c730>, method=<bound method EmailPlugin.get_email_address of <__main__.EmailPlugin object at 0x763767d6f640>>, stream_method=None), 'SendEmail': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='SendEmail', plugin_name='EmailPlugin', description='Given an e-mail and message body, send an e-email', parameters=[KernelParameterMetadata(name='subject', description='the subject of the email', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string', 'description': 'the subject of the email'}, include_in_function_choices=True), KernelParameterMetadata(name='body', description='the body of the email', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string', 'description': 'the body of the email'}, include_in_function_choices=True)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='the output is a string', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string', 'description': 'the output is a string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6fb50>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6f0d0>, method=<bound method EmailPlugin.send_email of <__main__.EmailPlugin object at 0x763767d6f640>>, stream_method=None)})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.add_plugin(plugin_name=\"EmailPlugin\", plugin=EmailPlugin())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effdf3ab",
   "metadata": {},
   "source": [
    "Let's also add a couple more plugins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abe150e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='TimePlugin', description=None, functions={'date': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='date', plugin_name='TimePlugin', description='Get the current date.', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6c1f0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6c460>, method=<bound method TimePlugin.date of TimePlugin()>, stream_method=None), 'date_matching_last_day_name': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='date_matching_last_day_name', plugin_name='TimePlugin', description='Get the date of the last day matching the supplied week day name in English.', parameters=[KernelParameterMetadata(name='day_name', description=None, default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6e1a0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6f820>, method=<bound method TimePlugin.date_matching_last_day_name of TimePlugin()>, stream_method=None), 'day': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='day', plugin_name='TimePlugin', description='Get the current day', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6f190>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6e860>, method=<bound method TimePlugin.day of TimePlugin()>, stream_method=None), 'dayOfWeek': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='dayOfWeek', plugin_name='TimePlugin', description='Get the current day of the week', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6f9d0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6f730>, method=<bound method TimePlugin.day_of_week of TimePlugin()>, stream_method=None), 'days_ago': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='days_ago', plugin_name='TimePlugin', description='Get the date of offset from today by a provided number of days', parameters=[KernelParameterMetadata(name='days', description=None, default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6f1f0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6fac0>, method=<bound method TimePlugin.days_ago of TimePlugin()>, stream_method=None), 'hour': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='hour', plugin_name='TimePlugin', description='Get the current hour', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6e470>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6f2e0>, method=<bound method TimePlugin.hour of TimePlugin()>, stream_method=None), 'hourNumber': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='hourNumber', plugin_name='TimePlugin', description='Get the current hour number', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6f070>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6cc40>, method=<bound method TimePlugin.hour_number of TimePlugin()>, stream_method=None), 'iso_date': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='iso_date', plugin_name='TimePlugin', description='Get the current date in iso format.', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767d6efe0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767e770a0>, method=<bound method TimePlugin.iso_date of TimePlugin()>, stream_method=None), 'minute': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='minute', plugin_name='TimePlugin', description='Get the current minute', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767e76350>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dc9ae0>, method=<bound method TimePlugin.minute of TimePlugin()>, stream_method=None), 'month': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='month', plugin_name='TimePlugin', description='Get the current month', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dc8e20>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dca890>, method=<bound method TimePlugin.month of TimePlugin()>, stream_method=None), 'month_number': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='month_number', plugin_name='TimePlugin', description='Get the current month number', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dca7d0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dcb100>, method=<bound method TimePlugin.month_number of TimePlugin()>, stream_method=None), 'now': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='now', plugin_name='TimePlugin', description='Get the current date and time in the local time zone', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dca830>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dcaf80>, method=<bound method TimePlugin.now of TimePlugin()>, stream_method=None), 'second': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='second', plugin_name='TimePlugin', description='Get the seconds on the current minute', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dcb9a0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dcb820>, method=<bound method TimePlugin.second of TimePlugin()>, stream_method=None), 'time': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='time', plugin_name='TimePlugin', description='Get the current time in the local time zone', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dcb9d0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dcafb0>, method=<bound method TimePlugin.time of TimePlugin()>, stream_method=None), 'timeZoneName': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='timeZoneName', plugin_name='TimePlugin', description='Get the current time zone name', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dc8a90>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dc9f30>, method=<bound method TimePlugin.time_zone_name of TimePlugin()>, stream_method=None), 'timeZoneOffset': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='timeZoneOffset', plugin_name='TimePlugin', description='Get the current time zone offset', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dca320>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dcba90>, method=<bound method TimePlugin.time_zone_offset of TimePlugin()>, stream_method=None), 'today': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='today', plugin_name='TimePlugin', description='Get the current date.', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dcb0d0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dc9cc0>, method=<bound method TimePlugin.today of TimePlugin()>, stream_method=None), 'utcNow': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='utcNow', plugin_name='TimePlugin', description='Get the current date and time in UTC', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dc9c60>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dc9b40>, method=<bound method TimePlugin.utc_now of TimePlugin()>, stream_method=None), 'year': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='year', plugin_name='TimePlugin', description='Get the current year', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dc9ab0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x763767dc90c0>, method=<bound method TimePlugin.year of TimePlugin()>, stream_method=None)})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel.core_plugins.math_plugin import MathPlugin\n",
    "from semantic_kernel.core_plugins.time_plugin import TimePlugin\n",
    "\n",
    "kernel.add_plugin(plugin_name=\"MathPlugin\", plugin=MathPlugin())\n",
    "kernel.add_plugin(plugin_name=\"TimePlugin\", plugin=TimePlugin())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06796ade",
   "metadata": {},
   "source": [
    "We will define our FunctionCallingStepPlanner and the questions we want to ask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06d08549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planners.function_calling_stepwise_planner import (\n",
    "    FunctionCallingStepwisePlanner,\n",
    "    FunctionCallingStepwisePlannerOptions,\n",
    ")\n",
    "\n",
    "questions = [\n",
    "    \"What is the current hour number, plus 5?\",\n",
    "    \"What is 387 minus 22? Email the solution to John and Mary.\",\n",
    "    \"Write a limerick, translate it to Spanish, and send it to Jane\",\n",
    "]\n",
    "\n",
    "options = FunctionCallingStepwisePlannerOptions(\n",
    "    max_iterations=10,\n",
    "    max_tokens=4000,\n",
    ")\n",
    "\n",
    "planner = FunctionCallingStepwisePlanner(service_id=service_id, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ed7874",
   "metadata": {},
   "source": [
    "Let's loop through the questions and invoke the planner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d00c6f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is the current hour number, plus 5?\n",
      "A: The current hour number plus 5 is 24.\n",
      "\n",
      "Chat history: <chat_history><message role=\"user\"><text>Original request: What is the current hour number, plus 5?\n",
      "\n",
      "You are in the process of helping the user fulfill this request using the following plan:\n",
      "To achieve the goal of finding the current hour number plus 5, we can follow these steps:\n",
      "\n",
      "1. Use the `TimePlugin-hourNumber` function to get the current hour number.\n",
      "2. Use the `MathPlugin-Add` function to add 5 to the current hour number obtained in step 1.\n",
      "\n",
      "Let's execute these steps.\n",
      "\n",
      "The user will ask you for help with each step.</text></message><message role=\"user\"><text>Perform the next step of the plan if there is more work to do. When you have reached a final answer, use the UserInteraction-SendFinalAnswer function to communicate this back to the user.</text></message><message role=\"assistant\" finish_reason=\"tool_calls\" ai_model_id=\"salekh-swedenc-gpt4o\"><function_call id=\"call_PCo3aDfkaR0iujajdrKPVYRo\" name=\"TimePlugin-hourNumber\">{}</function_call></message><message role=\"tool\"><function_result id=\"call_PCo3aDfkaR0iujajdrKPVYRo\" name=\"TimePlugin-hourNumber\">19</function_result></message><message role=\"user\"><text>Perform the next step of the plan if there is more work to do. When you have reached a final answer, use the UserInteraction-SendFinalAnswer function to communicate this back to the user.</text></message><message role=\"assistant\" finish_reason=\"tool_calls\" ai_model_id=\"salekh-swedenc-gpt4o\"><function_call id=\"call_vssk1NxWLAfNGgAexs27utOo\" name=\"MathPlugin-Add\">{\"input\":19,\"amount\":5}</function_call></message><message role=\"tool\"><function_result id=\"call_vssk1NxWLAfNGgAexs27utOo\" name=\"MathPlugin-Add\">24</function_result></message><message role=\"user\"><text>Perform the next step of the plan if there is more work to do. When you have reached a final answer, use the UserInteraction-SendFinalAnswer function to communicate this back to the user.</text></message><message role=\"assistant\" finish_reason=\"tool_calls\" ai_model_id=\"salekh-swedenc-gpt4o\"><function_call id=\"call_cJgXLH4p3oQvWDgd3NMczIvc\" name=\"UserInteraction-SendFinalAnswer\">{\"answer\":\"The current hour number plus 5 is 24.\"}</function_call></message></chat_history>\n",
      "\n",
      "Q: What is 387 minus 22? Email the solution to John and Mary.\n",
      "A: The result of 387 minus 22 is 365, and the solution has been emailed to both John and Mary successfully.\n",
      "\n",
      "Chat history: <chat_history><message role=\"user\"><text>Original request: What is 387 minus 22? Email the solution to John and Mary.\n",
      "\n",
      "You are in the process of helping the user fulfill this request using the following plan:\n",
      "To achieve the goal, we need to follow these steps:\n",
      "\n",
      "1. Calculate the result of 387 minus 22 using the MathPlugin-Subtract function.\n",
      "2. Get the email address of John using the EmailPlugin-GetEmailAddress function.\n",
      "3. Get the email address of Mary using the EmailPlugin-GetEmailAddress function.\n",
      "4. Send the calculated result to John's email using the EmailPlugin-SendEmail function.\n",
      "5. Send the calculated result to Mary's email using the EmailPlugin-SendEmail function.\n",
      "\n",
      "Let's start with step 1.\n",
      "\n",
      "The user will ask you for help with each step.</text></message><message role=\"user\"><text>Perform the next step of the plan if there is more work to do. When you have reached a final answer, use the UserInteraction-SendFinalAnswer function to communicate this back to the user.</text></message><message role=\"assistant\" finish_reason=\"tool_calls\" ai_model_id=\"salekh-swedenc-gpt4o\"><function_call id=\"call_DOwihrh7fzc7V5kre3bf28ye\" name=\"MathPlugin-Subtract\">{\"input\":387,\"amount\":22}</function_call></message><message role=\"tool\"><function_result id=\"call_DOwihrh7fzc7V5kre3bf28ye\" name=\"MathPlugin-Subtract\">365</function_result></message><message role=\"user\"><text>Perform the next step of the plan if there is more work to do. When you have reached a final answer, use the UserInteraction-SendFinalAnswer function to communicate this back to the user.</text></message><message role=\"assistant\" finish_reason=\"tool_calls\" ai_model_id=\"salekh-swedenc-gpt4o\"><function_call id=\"call_HYC6kpxsEHpe2fU2fzkgFXG6\" name=\"EmailPlugin-GetEmailAddress\">{\"input\": \"John\"}</function_call><function_call id=\"call_tBstB5Ztbj7upZBV68V7ivkp\" name=\"EmailPlugin-GetEmailAddress\">{\"input\": \"Mary\"}</function_call></message><message role=\"tool\"><function_result id=\"call_HYC6kpxsEHpe2fU2fzkgFXG6\" name=\"EmailPlugin-GetEmailAddress\">johndoe1234@example.com</function_result></message><message role=\"tool\"><function_result id=\"call_tBstB5Ztbj7upZBV68V7ivkp\" name=\"EmailPlugin-GetEmailAddress\">maryjones8765@example.com</function_result></message><message role=\"user\"><text>Perform the next step of the plan if there is more work to do. When you have reached a final answer, use the UserInteraction-SendFinalAnswer function to communicate this back to the user.</text></message><message role=\"assistant\" finish_reason=\"tool_calls\" ai_model_id=\"salekh-swedenc-gpt4o\"><function_call id=\"call_IE5mxNWyRGJ5O7jWOCpzCnA4\" name=\"EmailPlugin-SendEmail\">{\"subject\": \"Calculated Solution\", \"body\": \"The result of 387 minus 22 is 365.\"}</function_call><function_call id=\"call_zi2yKuSFCOMdk7ccLvV2jmpA\" name=\"EmailPlugin-SendEmail\">{\"subject\": \"Calculated Solution\", \"body\": \"The result of 387 minus 22 is 365.\"}</function_call></message><message role=\"tool\"><function_result id=\"call_IE5mxNWyRGJ5O7jWOCpzCnA4\" name=\"EmailPlugin-SendEmail\">Email sent with subject: Calculated Solution and body: The result of 387 minus 22 is 365.</function_result></message><message role=\"tool\"><function_result id=\"call_zi2yKuSFCOMdk7ccLvV2jmpA\" name=\"EmailPlugin-SendEmail\">Email sent with subject: Calculated Solution and body: The result of 387 minus 22 is 365.</function_result></message><message role=\"user\"><text>Perform the next step of the plan if there is more work to do. When you have reached a final answer, use the UserInteraction-SendFinalAnswer function to communicate this back to the user.</text></message><message role=\"assistant\" finish_reason=\"tool_calls\" ai_model_id=\"salekh-swedenc-gpt4o\"><function_call id=\"call_GSZVqqHqTPtZRjWUwcwHDRd5\" name=\"UserInteraction-SendFinalAnswer\">{\"answer\":\"The result of 387 minus 22 is 365, and the solution has been emailed to both John and Mary successfully.\"}</function_call></message></chat_history>\n",
      "\n",
      "Q: Write a limerick, translate it to Spanish, and send it to Jane\n",
      "A: The Spanish limerick has been successfully sent to Jane at janedoe4321@example.com.\n",
      "\n",
      "Chat history: <chat_history><message role=\"user\"><text>Original request: Write a limerick, translate it to Spanish, and send it to Jane\n",
      "\n",
      "You are in the process of helping the user fulfill this request using the following plan:\n",
      "To achieve the goal, we need to follow these steps:\n",
      "\n",
      "1. Write a limerick in English.\n",
      "2. Translate the limerick to Spanish.\n",
      "3. Use the EmailPlugin-GetEmailAddress function to find Jane's email address.\n",
      "4. Use the EmailPlugin-SendEmail function to send the translated limerick to Jane.\n",
      "\n",
      "Let's start with step 1: writing a limerick in English.\n",
      "\n",
      "**Limerick:**\n",
      "There once was a cat from Peru,\n",
      "Who dreamt of a life in a zoo.\n",
      "He packed up his hat,\n",
      "And left in a spat,\n",
      "Now he roams with the kangaroo.\n",
      "\n",
      "Now, let's translate it to Spanish for step 2.\n",
      "\n",
      "**Translated Limerick:**\n",
      "Había una vez un gato de Perú,\n",
      "Que soñaba con una vida en un zoo.\n",
      "Empacó su sombrero,\n",
      "Y se fue en un arrebato,\n",
      "Ahora vaga con el canguro.\n",
      "\n",
      "Next, we need to find Jane's email address using the EmailPlugin-GetEmailAddress function. Let's proceed with step 3.\n",
      "\n",
      "The user will ask you for help with each step.</text></message><message role=\"user\"><text>Perform the next step of the plan if there is more work to do. When you have reached a final answer, use the UserInteraction-SendFinalAnswer function to communicate this back to the user.</text></message><message role=\"assistant\" finish_reason=\"tool_calls\" ai_model_id=\"salekh-swedenc-gpt4o\"><function_call id=\"call_8KCZpU9HsPAiGoadBs9dLEro\" name=\"EmailPlugin-GetEmailAddress\">{\"input\":\"Jane\"}</function_call></message><message role=\"tool\"><function_result id=\"call_8KCZpU9HsPAiGoadBs9dLEro\" name=\"EmailPlugin-GetEmailAddress\">janedoe4321@example.com</function_result></message><message role=\"user\"><text>Perform the next step of the plan if there is more work to do. When you have reached a final answer, use the UserInteraction-SendFinalAnswer function to communicate this back to the user.</text></message><message role=\"assistant\" finish_reason=\"tool_calls\" ai_model_id=\"salekh-swedenc-gpt4o\"><function_call id=\"call_dRj29Sm4qp4Fc6ekqaOLMJah\" name=\"EmailPlugin-SendEmail\">{\"subject\":\"A Spanish Limerick for You\",\"body\":\"Había una vez un gato de Perú,\\nQue soñaba con una vida en un zoo.\\nEmpacó su sombrero,\\nY se fue en un arrebato,\\nAhora vaga con el canguro.\",\"to\":\"janedoe4321@example.com\"}</function_call></message><message role=\"tool\"><function_result id=\"call_dRj29Sm4qp4Fc6ekqaOLMJah\" name=\"EmailPlugin-SendEmail\">Email sent with subject: A Spanish Limerick for You and body: Había una vez un gato de Perú,\n",
      "Que soñaba con una vida en un zoo.\n",
      "Empacó su sombrero,\n",
      "Y se fue en un arrebato,\n",
      "Ahora vaga con el canguro.</function_result></message><message role=\"user\"><text>Perform the next step of the plan if there is more work to do. When you have reached a final answer, use the UserInteraction-SendFinalAnswer function to communicate this back to the user.</text></message><message role=\"assistant\" finish_reason=\"tool_calls\" ai_model_id=\"salekh-swedenc-gpt4o\"><function_call id=\"call_RRNEQ3iaoBqhtupteVlAgkKl\" name=\"UserInteraction-SendFinalAnswer\">{\"answer\":\"The Spanish limerick has been successfully sent to Jane at janedoe4321@example.com.\"}</function_call></message></chat_history>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    result = await planner.invoke(kernel, question)\n",
    "    print(f\"Q: {question}\\nA: {result.final_answer}\\n\")\n",
    "\n",
    "    # Uncomment the following line to view the planner's process for completing the request\n",
    "    print(f\"Chat history: {result.chat_history}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff90ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
