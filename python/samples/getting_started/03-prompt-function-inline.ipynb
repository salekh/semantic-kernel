{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c93ac5b",
   "metadata": {},
   "source": [
    "# Running Prompt Functions Inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85226c",
   "metadata": {},
   "source": [
    "Import Semantic Kernel SDK from pypi.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a94d2b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semantic-kernel in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (1.18.2)\n",
      "Requirement already satisfied: aiohttp~=3.8 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (3.11.11)\n",
      "Requirement already satisfied: cloudevents~=1.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (1.11.0)\n",
      "Requirement already satisfied: pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (2.9.2)\n",
      "Requirement already satisfied: pydantic-settings~=2.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (2.7.1)\n",
      "Requirement already satisfied: defusedxml~=0.7 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: azure-identity~=1.13 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (1.19.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (2.1.2)\n",
      "Requirement already satisfied: openai~=1.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (1.59.9)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (0.19.4)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (1.29.0)\n",
      "Requirement already satisfied: prance~=23.6.21.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (23.6.21.0)\n",
      "Requirement already satisfied: pybars4~=0.9 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (0.9.13)\n",
      "Requirement already satisfied: jinja2~=3.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (3.1.5)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from semantic-kernel) (1.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from aiohttp~=3.8->semantic-kernel) (1.18.3)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from azure-identity~=1.13->semantic-kernel) (1.32.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from azure-identity~=1.13->semantic-kernel) (44.0.0)\n",
      "Requirement already satisfied: msal>=1.30.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from azure-identity~=1.13->semantic-kernel) (1.31.1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from azure-identity~=1.13->semantic-kernel) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from azure-identity~=1.13->semantic-kernel) (4.12.2)\n",
      "Requirement already satisfied: deprecation<3.0,>=2.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from cloudevents~=1.0->semantic-kernel) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from jinja2~=3.1->semantic-kernel) (3.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openai~=1.0->semantic-kernel) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openai~=1.0->semantic-kernel) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openai~=1.0->semantic-kernel) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openai~=1.0->semantic-kernel) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openai~=1.0->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openai~=1.0->semantic-kernel) (4.67.1)\n",
      "Requirement already satisfied: isodate in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.3.3)\n",
      "Requirement already satisfied: more-itertools in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.6.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.6.3)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: parse in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (1.20.2)\n",
      "Requirement already satisfied: werkzeug in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (3.1.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from opentelemetry-api~=1.24->semantic-kernel) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from opentelemetry-api~=1.24->semantic-kernel) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from opentelemetry-sdk~=1.24->semantic-kernel) (0.50b0)\n",
      "Requirement already satisfied: chardet>=3.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from prance~=23.6.21.0->semantic-kernel) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.10 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from prance~=23.6.21.0->semantic-kernel) (0.18.10)\n",
      "Requirement already satisfied: requests>=2.25 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from prance~=23.6.21.0->semantic-kernel) (2.32.3)\n",
      "Requirement already satisfied: six~=1.15 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from prance~=23.6.21.0->semantic-kernel) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from prance~=23.6.21.0->semantic-kernel) (24.1)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from pybars4~=0.9->semantic-kernel) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0->semantic-kernel) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0->semantic-kernel) (2.23.4)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from pydantic-settings~=2.0->semantic-kernel) (1.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai~=1.0->semantic-kernel) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai~=1.0->semantic-kernel) (3.10)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from cryptography>=2.5->azure-identity~=1.13->semantic-kernel) (1.17.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.24->semantic-kernel) (1.17.2)\n",
      "Requirement already satisfied: certifi in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel) (3.20.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.22.3)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (6.0.2)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (0.4.4)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity~=1.13->semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from msal-extensions>=1.2.0->azure-identity~=1.13->semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: rfc3339-validator in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel) (1.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.25->prance~=23.6.21.0->semantic-kernel) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from requests>=2.25->prance~=23.6.21.0->semantic-kernel) (2.2.3)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from ruamel.yaml>=0.17.10->prance~=23.6.21.0->semantic-kernel) (0.2.12)\n",
      "Requirement already satisfied: pycparser in /home/sanchitalekh/miniconda3/envs/llm/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity~=1.13->semantic-kernel) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.18.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: if using a virtual environment, do not run this cell\n",
    "%pip install -U semantic-kernel\n",
    "from semantic_kernel import __version__\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c704e54b",
   "metadata": {},
   "source": [
    "Initial configuration for the notebook to run properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ebb95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure paths are correct for the imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_dir = os.path.abspath(\"\")\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "\n",
    "sys.path.append(grandparent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb77b5",
   "metadata": {},
   "source": [
    "### Configuring the Kernel\n",
    "\n",
    "Let's get started with the necessary configuration to run Semantic Kernel. For Notebooks, we require a `.env` file with the proper settings for the model you use. Create a new file named `.env` and place it in this directory. Copy the contents of the `.env.example` file from this directory and paste it into the `.env` file that you just created.\n",
    "\n",
    "**NOTE: Please make sure to include `GLOBAL_LLM_SERVICE` set to either OpenAI, AzureOpenAI, or HuggingFace in your .env file. If this setting is not included, the Service will default to AzureOpenAI.**\n",
    "\n",
    "#### Option 1: using OpenAI\n",
    "\n",
    "Add your [OpenAI Key](https://openai.com/product/) key to your `.env` file (org Id only if you have multiple orgs):\n",
    "\n",
    "```\n",
    "GLOBAL_LLM_SERVICE=\"OpenAI\"\n",
    "OPENAI_API_KEY=\"sk-...\"\n",
    "OPENAI_ORG_ID=\"\"\n",
    "OPENAI_CHAT_MODEL_ID=\"\"\n",
    "OPENAI_TEXT_MODEL_ID=\"\"\n",
    "OPENAI_EMBEDDING_MODEL_ID=\"\"\n",
    "```\n",
    "The names should match the names used in the `.env` file, as shown above.\n",
    "\n",
    "#### Option 2: using Azure OpenAI\n",
    "\n",
    "Add your [Azure OpenAI Service key](https://learn.microsoft.com/azure/cognitive-services/openai/quickstart?pivots=programming-language-studio) settings to the `.env` file in the same folder:\n",
    "\n",
    "```\n",
    "GLOBAL_LLM_SERVICE=\"AzureOpenAI\"\n",
    "AZURE_OPENAI_API_KEY=\"...\"\n",
    "AZURE_OPENAI_ENDPOINT=\"https://...\"\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_TEXT_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=\"...\"\n",
    "AZURE_OPENAI_API_VERSION=\"...\"\n",
    "```\n",
    "The names should match the names used in the `.env` file, as shown above.\n",
    "\n",
    "For more advanced configuration, please follow the steps outlined in the [setup guide](./CONFIGURING_THE_KERNEL.md)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40201641",
   "metadata": {},
   "source": [
    "The [previous notebook](./02-running-prompts-from-file.ipynb)\n",
    "showed how to define a semantic function using a prompt template stored on a file.\n",
    "\n",
    "In this notebook, we'll show how to use the Semantic Kernel to define functions inline with your python code. This can be useful in a few scenarios:\n",
    "\n",
    "- Dynamically generating the prompt using complex rules at runtime\n",
    "- Writing prompts by editing Python code instead of TXT files.\n",
    "- Easily creating demos, like this document\n",
    "\n",
    "Prompt templates are defined using the SK template language, which allows to reference variables and functions. Read [this doc](https://aka.ms/sk/howto/configurefunction) to learn more about the design decisions for prompt templating.\n",
    "\n",
    "For now we'll use only the `{{$input}}` variable, and see more complex templates later.\n",
    "\n",
    "Almost all semantic function prompts have a reference to `{{$input}}`, which is the default way\n",
    "a user can import content from the context variables.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d90b0c13",
   "metadata": {},
   "source": [
    "Prepare a semantic kernel instance first, loading also the AI service settings defined in the [Setup notebook](00-getting-started.ipynb):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0377f42e",
   "metadata": {},
   "source": [
    "Let's define our kernel for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462b281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.kernel import Kernel\n",
    "\n",
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "734d121f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using service type: Service.AzureOpenAI\n"
     ]
    }
   ],
   "source": [
    "from services import Service\n",
    "\n",
    "from samples.service_settings import ServiceSettings\n",
    "\n",
    "service_settings = ServiceSettings.create()\n",
    "\n",
    "# Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
    "selectedService = (\n",
    "    Service.AzureOpenAI\n",
    "    if service_settings.global_llm_service is None\n",
    "    else Service(service_settings.global_llm_service.lower())\n",
    ")\n",
    "print(f\"Using service type: {selectedService}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06740170",
   "metadata": {},
   "source": [
    "We now configure our Chat Completion service on the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3712b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all services so that this cell can be re-run without restarting the kernel\n",
    "kernel.remove_all_services()\n",
    "\n",
    "service_id = None\n",
    "if selectedService == Service.OpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        OpenAIChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )\n",
    "elif selectedService == Service.AzureOpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "589733c5",
   "metadata": {},
   "source": [
    "Let's use a prompt to create a semantic function used to summarize content, allowing for some creativity and a sufficient number of tokens.\n",
    "\n",
    "The function will take in input the text to summarize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae29c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings, OpenAIChatPromptExecutionSettings\n",
    "from semantic_kernel.prompt_template import InputVariable, PromptTemplateConfig\n",
    "\n",
    "prompt = \"\"\"{{$input}}\n",
    "Summarize the content above.\n",
    "\"\"\"\n",
    "\n",
    "if selectedService == Service.OpenAI:\n",
    "    execution_settings = OpenAIChatPromptExecutionSettings(\n",
    "        service_id=service_id,\n",
    "        ai_model_id=\"gpt-3.5-turbo\",\n",
    "        max_tokens=2000,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "elif selectedService == Service.AzureOpenAI:\n",
    "    execution_settings = AzureChatPromptExecutionSettings(\n",
    "        service_id=service_id,\n",
    "        ai_model_id=\"gpt-35-turbo\",\n",
    "        max_tokens=2000,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    name=\"summarize\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"The user input\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=execution_settings,\n",
    ")\n",
    "\n",
    "summarize = kernel.add_function(\n",
    "    function_name=\"summarizeFunc\",\n",
    "    plugin_name=\"summarizePlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f26b90c4",
   "metadata": {},
   "source": [
    "Set up some content to summarize, here's a book review of the recent book by Ruchir Sharma called \"What went wrong with Capitalism\". The review was generated by AI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "314557fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "Ruchir Sharma’s “What Went Wrong with Capitalism” offers a compelling critique of modern economic systems, delving into the intricate relationship between government intervention and market dynamics. Sharma’s analysis is both historical and contemporary, providing readers with a nuanced understanding of how capitalism has evolved and where it has faltered.\n",
    "The book begins by challenging the widely held belief in a golden age of small government. Sharma argues that this notion is largely a myth, pointing out that even during the Reagan and Thatcher eras, government influence continued to grow. This sets the stage for a broader discussion on the expanding role of government since the 1930s, highlighting how government spending has significantly increased over the decades.\n",
    "One of the central themes of the book is the impact of easy money policies. Sharma critiques central bank interventions and low interest rates, which he believes have distorted capitalism by encouraging excessive risk-taking and creating a culture of debt. This, in turn, has led to a bailout culture, where the expectation of government bailouts during crises has fostered moral hazard in financial decision-making.\n",
    "Sharma also explores the historical evolution of American economic thought, drawing on the differing views of figures like Alexander Hamilton and Thomas Jefferson. This historical perspective enriches the reader’s understanding of the ideological foundations of American capitalism and how these ideas have shaped contemporary economic policies.\n",
    "The book is particularly critical of the permanent adoption of Keynesian deficit spending, which was originally intended as a temporary measure during crises. Sharma warns that this approach has led to rising government deficits and an impending global economic crisis. He argues that the continuous rise of big government poses significant risks to economic stability and growth.\n",
    "In addition to fiscal policies, Sharma examines the increase in government regulations across industries, which he believes has further expanded the state’s role in the economy. He also touches on the growth of defense and intelligence agencies, contributing to what he describes as the national security state.\n",
    "Overall, “What Went Wrong with Capitalism” is a thought-provoking and insightful analysis of the challenges facing modern capitalism. Sharma’s critique is well-researched and balanced, offering readers a comprehensive overview of the complex interplay between government intervention and market forces. Whether you are a student of economics, a policy maker, or simply someone interested in understanding the current economic landscape, this book provides valuable insights into the factors that have shaped and continue to influence capitalism today.\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf0f2330",
   "metadata": {},
   "source": [
    "...and run the summary function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b0e3b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruchir Sharma's book, \"What Went Wrong with Capitalism,\" offers a critical examination of modern economic systems, focusing on the interplay between government intervention and market dynamics. Sharma debunks the myth of a golden age of small government, noting that government influence has grown since the 1930s, even during the Reagan and Thatcher eras. A central theme is the impact of easy money policies and central bank interventions, which Sharma argues have encouraged excessive risk-taking and created a culture of debt, leading to a bailout culture and moral hazard. He critiques the permanent adoption of Keynesian deficit spending, warning that it has led to rising government deficits and potential economic crises. Sharma also discusses the increase in government regulations and the expansion of defense and intelligence agencies, contributing to a national security state. The book provides a historical perspective on American economic thought and offers a comprehensive analysis of the challenges facing modern capitalism, valuable for students, policymakers, and anyone interested in understanding the current economic landscape.\n"
     ]
    }
   ],
   "source": [
    "summary = await kernel.invoke(summarize, input=input_text)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c2c1262",
   "metadata": {},
   "source": [
    "# Using ChatCompletion for Semantic Plugins\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29b59b28",
   "metadata": {},
   "source": [
    "You can also use chat completion models (like `gpt-35-turbo` and `gpt4`) for creating plugins. Normally you would have to tweak the API to accommodate for a system and user role, but SK abstracts that away for you by using `kernel.add_service` and `AzureChatCompletion` or `OpenAIChatCompletion`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4777f447",
   "metadata": {},
   "source": [
    "Here's one more example of how to write an inline Semantic Function that gives a TLDR for a piece of text using a ChatCompletion model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5886aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.remove_all_services()\n",
    "\n",
    "service_id = None\n",
    "if selectedService == Service.OpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        OpenAIChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )\n",
    "elif selectedService == Service.AzureOpenAI:\n",
    "    from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "    service_id = \"default\"\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=service_id,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea8128c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: Robots prioritize human safety first.\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings, OpenAIChatPromptExecutionSettings\n",
    "\n",
    "prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Give me the TLDR in 5 words or less.\n",
    "\"\"\"\n",
    "\n",
    "text = \"\"\"\n",
    "    1) A robot may not injure a human being or, through inaction,\n",
    "    allow a human being to come to harm.\n",
    "\n",
    "    2) A robot must obey orders given it by human beings except where\n",
    "    such orders would conflict with the First Law.\n",
    "\n",
    "    3) A robot must protect its own existence as long as such protection\n",
    "    does not conflict with the First or Second Law.\n",
    "\"\"\"\n",
    "\n",
    "if selectedService == Service.OpenAI:\n",
    "    execution_settings = OpenAIChatPromptExecutionSettings(\n",
    "        service_id=service_id,\n",
    "        ai_model_id=\"gpt-3.5-turbo\",\n",
    "        max_tokens=2000,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "elif selectedService == Service.AzureOpenAI:\n",
    "    execution_settings = AzureChatPromptExecutionSettings(\n",
    "        service_id=service_id,\n",
    "        ai_model_id=\"gpt-35-turbo\",\n",
    "        max_tokens=2000,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    name=\"tldr\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"The user input\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=execution_settings,\n",
    ")\n",
    "\n",
    "tldr_function = kernel.add_function(\n",
    "    function_name=\"tldrFunction\",\n",
    "    plugin_name=\"tldrPlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")\n",
    "\n",
    "summary = await kernel.invoke(tldr_function, input=text)\n",
    "\n",
    "print(f\"Output: {summary}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
